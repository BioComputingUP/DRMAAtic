ClusterName=cluster
ControlMachine=perse.local
ControlAddr=172.21.2.90
SlurmUser=root

SlurmctldPort=6817
SlurmdPort=6818

# AUTHENTICATION - All nodes must have the same munge.key file (in /etc/munge)
AuthType=auth/munge

MailProg=/opt/slurm-mail/bin/slurm-spool-mail.py
MpiDefault=pmi2
#MpiParams=ports=#-#
ProctrackType=proctrack/cgroup
ReturnToService=2
SlurmctldPidFile=/run/slurmctld.pid
SlurmdPidFile=/run/slurmd.pid
SlurmdSpoolDir=/var/lib/slurm-llnl/slurmd
StateSaveLocation=/var/lib/slurm-llnl/slurmctld
SwitchType=switch/none
TaskPlugin=task/affinity
#
#
# TIMERS
#KillWait=30
#MinJobAge=300
#SlurmctldTimeout=120
#SlurmdTimeout=300
#
#
# SCHEDULING
FastSchedule=1
SchedulerType=sched/backfill
SchedulerParameters=bf_continue,bf_max_job_test=5000,kill_invalid_depend
# from 20+ use DependencyParameters instead of SchedulerParameters
#DependencyParameters=kill_invalid_depend
SelectType=select/cons_res
#SelectTypeParameters=CR_CPU
SelectTypeParameters=CR_CPU_Memory
#
# Activate the Multifactor Job Priority Plugin with decay
PriorityType=priority/multifactor
# 2 week half-life
PriorityDecayHalfLife=14-0
# The larger the job, the greater its job size priority.
PriorityFavorSmall=NO
# The job's age factor reaches 1.0 after waiting in the
# queue for 2 weeks.
PriorityMaxAge=14-0
# This next group determines the weighting of each of the
# components of the Multifactor Job Priority Plugin.
# The default value for each of the following is 1.
PriorityWeightAge=1000
PriorityWeightFairshare=10000
PriorityWeightJobSize=1000
PriorityWeightPartition=1000
PriorityWeightQOS=0 # don't use the qos factor

# LOGGING
# SlurmctldDebug=3
# SlurmdDebug=info
SlurmctldLogFile=/var/log/slurm-llnl/slurmctld.log
SlurmdLogFile=/var/log/slurm-llnl/slurmd.log

# ACCOUNTING
AccountingStorageType=accounting_storage/slurmdbd
AccountingStorageHost=perse
AccountingStoragePort=6819
AccountingStorageLoc=slurm_acct_db
JobAcctGatherFrequency=30
JobAcctGatherType=jobacct_gather/cgroup
#
MaxJobCount=50000
MaxArraySize=100000
DefMemPerCPU=1536
#
# COMPUTE NODES
# man slurm.conf says not to use CoresPerSocket/ThreadsPerCore if ThreadsPerCore>1 and you want per thread allocation
NodeName=melinoe,orfne,menta,medusa,leuce,aletto,megera,tisifone CPUs=16 TmpDisk=512000 RealMemory=32073
NodeName=ecate CPUs=48 TmpDisk=512000 RealMemory=94208
NodeName=bia CPUs=20 TmpDisk=300000 RealMemory=38000
PartitionName=ultra Nodes=ecate MaxTime=INFINITE State=UP
PartitionName=mega Nodes=bia MaxTime=INFINITE State=UP
PartitionName=super Nodes=melinoe,orfne,menta,medusa,leuce,aletto,megera,tisifone Default=YES MaxTime=INFINITE State=UP
PartitionName=long Nodes=melinoe,orfne,menta,medusa,megera,tisifone MaxTime=INFINITE State=UP LLN=YES
PartitionName=long-all Nodes=melinoe,orfne,menta,medusa,megera,tisifone,ecate,bia MaxTime=INFINITE State=UP LLN=YES

